{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T04:02:03.015693Z",
     "iopub.status.busy": "2025-11-22T04:02:03.015252Z",
     "iopub.status.idle": "2025-11-22T04:02:03.019042Z",
     "shell.execute_reply": "2025-11-22T04:02:03.018319Z",
     "shell.execute_reply.started": "2025-11-22T04:02:03.015673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T04:01:35.977902Z",
     "iopub.status.busy": "2025-11-22T04:01:35.977608Z",
     "iopub.status.idle": "2025-11-22T04:01:41.337226Z",
     "shell.execute_reply": "2025-11-22T04:01:41.336512Z",
     "shell.execute_reply.started": "2025-11-22T04:01:35.977881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers sentencepiece accelerate -q\n",
    "\n",
    "# !pip install optuna transformers -q\n",
    "!pip install transformers contractions -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T04:01:41.338852Z",
     "iopub.status.busy": "2025-11-22T04:01:41.338615Z",
     "iopub.status.idle": "2025-11-22T04:02:03.014579Z",
     "shell.execute_reply": "2025-11-22T04:02:03.013832Z",
     "shell.execute_reply.started": "2025-11-22T04:01:41.338828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import RobertaTokenizerFast, RobertaModel, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "from contractions import fix as fix_contractions\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 8           # roberta-large â‡’ keep small\n",
    "EPOCHS = 13              # enough for large model\n",
    "LR = 1e-5                # slower LR for large models\n",
    "\n",
    "\n",
    "print(\"The Variables\")\n",
    "print(f\"Max Length : {MAX_LEN} | Batch Size: {BATCH_SIZE} | Epochs: {EPOCHS} | Learning Rate: {LR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path= '../Data/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T02:04:10.631452Z",
     "iopub.status.busy": "2025-11-22T02:04:10.630957Z",
     "iopub.status.idle": "2025-11-22T02:04:10.670268Z",
     "shell.execute_reply": "2025-11-22T02:04:10.669497Z",
     "shell.execute_reply.started": "2025-11-22T02:04:10.631426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T02:04:12.105943Z",
     "iopub.status.busy": "2025-11-22T02:04:12.105455Z",
     "iopub.status.idle": "2025-11-22T02:04:12.118180Z",
     "shell.execute_reply": "2025-11-22T02:04:12.117345Z",
     "shell.execute_reply.started": "2025-11-22T02:04:12.105919Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# X = input text\n",
    "X = df['text']\n",
    "\n",
    "# y = emotion labels (multi-label target)\n",
    "y = df[['anger', 'fear', 'joy', 'sadness', 'surprise']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T02:04:14.145607Z",
     "iopub.status.busy": "2025-11-22T02:04:14.145336Z",
     "iopub.status.idle": "2025-11-22T02:04:14.153497Z",
     "shell.execute_reply": "2025-11-22T02:04:14.152824Z",
     "shell.execute_reply.started": "2025-11-22T02:04:14.145584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 6: Train-test split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    X.tolist(),y.values, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T02:04:15.726517Z",
     "iopub.status.busy": "2025-11-22T02:04:15.725884Z",
     "iopub.status.idle": "2025-11-22T02:04:15.732357Z",
     "shell.execute_reply": "2025-11-22T02:04:15.731520Z",
     "shell.execute_reply.started": "2025-11-22T02:04:15.726475Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '<URL>', text)\n",
    "    text = re.sub(r'@\\w+', '<USER>', text)\n",
    "    text = fix_contractions(text)\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T02:04:18.025789Z",
     "iopub.status.busy": "2025-11-22T02:04:18.025498Z",
     "iopub.status.idle": "2025-11-22T02:04:18.504825Z",
     "shell.execute_reply": "2025-11-22T02:04:18.504224Z",
     "shell.execute_reply.started": "2025-11-22T02:04:18.025747Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train = [clean_text(x) for x in train_texts]\n",
    "X_val   = [clean_text(x) for x in val_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T02:04:20.806955Z",
     "iopub.status.busy": "2025-11-22T02:04:20.806211Z",
     "iopub.status.idle": "2025-11-22T02:04:22.689254Z",
     "shell.execute_reply": "2025-11-22T02:04:22.688408Z",
     "shell.execute_reply.started": "2025-11-22T02:04:20.806923Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-large\")\n",
    "\n",
    "def encode_batch(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T02:04:24.421002Z",
     "iopub.status.busy": "2025-11-22T02:04:24.420699Z",
     "iopub.status.idle": "2025-11-22T02:04:25.025317Z",
     "shell.execute_reply": "2025-11-22T02:04:25.024534Z",
     "shell.execute_reply.started": "2025-11-22T02:04:24.420979Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_enc = encode_batch(X_train)\n",
    "val_enc   = encode_batch(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T02:04:27.185436Z",
     "iopub.status.busy": "2025-11-22T02:04:27.185138Z",
     "iopub.status.idle": "2025-11-22T02:04:27.190854Z",
     "shell.execute_reply": "2025-11-22T02:04:27.190080Z",
     "shell.execute_reply.started": "2025-11-22T02:04:27.185413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: v[idx] for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T02:04:29.565521Z",
     "iopub.status.busy": "2025-11-22T02:04:29.565235Z",
     "iopub.status.idle": "2025-11-22T02:04:29.569507Z",
     "shell.execute_reply": "2025-11-22T02:04:29.568502Z",
     "shell.execute_reply.started": "2025-11-22T02:04:29.565501Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = EmotionDataset(train_enc, train_labels)\n",
    "val_dataset   = EmotionDataset(val_enc, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T02:04:31.606243Z",
     "iopub.status.busy": "2025-11-22T02:04:31.605589Z",
     "iopub.status.idle": "2025-11-22T02:04:31.610635Z",
     "shell.execute_reply": "2025-11-22T02:04:31.609766Z",
     "shell.execute_reply.started": "2025-11-22T02:04:31.606216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T02:04:34.045588Z",
     "iopub.status.busy": "2025-11-22T02:04:34.045325Z",
     "iopub.status.idle": "2025-11-22T02:04:34.051208Z",
     "shell.execute_reply": "2025-11-22T02:04:34.050285Z",
     "shell.execute_reply.started": "2025-11-22T02:04:34.045568Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self, num_labels=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.roberta = RobertaModel.from_pretrained(\"roberta-large\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.norm = nn.LayerNorm(1024)  # roberta-large has the hidden dim = 1024\n",
    "        self.classifier = nn.Linear(1024, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden = out.last_hidden_state  # (B, L, 1024)\n",
    "\n",
    "        # mean pooling\n",
    "        masked = hidden * attention_mask.unsqueeze(-1)\n",
    "        pooled = masked.sum(1) / attention_mask.sum(1, keepdim=True)\n",
    "\n",
    "        x = self.norm(pooled)\n",
    "        x = self.dropout(x)\n",
    "        return self.classifier(x)   # raw logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Model:\n",
    "model = EmotionClassifier(num_labels=5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.AdamW([\n",
    "    {\"params\": model.roberta.parameters(), \"lr\": LR},\n",
    "    {\"params\": model.classifier.parameters(), \"lr\": 3e-5},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T02:04:36.825561Z",
     "iopub.status.busy": "2025-11-22T02:04:36.825279Z",
     "iopub.status.idle": "2025-11-22T02:04:43.777240Z",
     "shell.execute_reply": "2025-11-22T02:04:43.776418Z",
     "shell.execute_reply.started": "2025-11-22T02:04:36.825539Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_training_steps = len(train_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * num_training_steps),\n",
    "    num_training_steps=num_training_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T02:04:43.778755Z",
     "iopub.status.busy": "2025-11-22T02:04:43.778494Z",
     "iopub.status.idle": "2025-11-22T02:04:43.784060Z",
     "shell.execute_reply": "2025-11-22T02:04:43.783144Z",
     "shell.execute_reply.started": "2025-11-22T02:04:43.778737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of epochs:\", EPOCHS)\n",
    "print(\"Max Length: \", MAX_LEN)\n",
    "def train_epoch(model, loader, optimizer, scheduler, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        ids = batch[\"input_ids\"].to(device)\n",
    "        mask = batch[\"attention_mask\"].to(device)\n",
    "        y = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(ids, mask)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T02:04:46.546143Z",
     "iopub.status.busy": "2025-11-22T02:04:46.545354Z",
     "iopub.status.idle": "2025-11-22T02:04:46.552991Z",
     "shell.execute_reply": "2025-11-22T02:04:46.552051Z",
     "shell.execute_reply.started": "2025-11-22T02:04:46.546109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            ids = batch[\"input_ids\"].to(device)\n",
    "            mask = batch[\"attention_mask\"].to(device)\n",
    "            y = batch[\"labels\"].to(device)\n",
    "\n",
    "            logits = model(ids, mask)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            pred = (probs > threshold).long()\n",
    "\n",
    "            preds.extend(pred.cpu().tolist())\n",
    "            trues.extend(y.cpu().tolist())\n",
    "\n",
    "    return f1_score(trues, preds, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T02:05:45.711511Z",
     "iopub.status.busy": "2025-11-22T02:05:45.710896Z",
     "iopub.status.idle": "2025-11-22T02:05:45.714975Z",
     "shell.execute_reply": "2025-11-22T02:05:45.714083Z",
     "shell.execute_reply.started": "2025-11-22T02:05:45.711485Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, criterion)\n",
    "    val_f1 = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {train_loss:.4f} | Val F1: {val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = \"../Data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-22T02:05:33.131615Z",
     "iopub.status.idle": "2025-11-22T02:05:33.131883Z",
     "shell.execute_reply": "2025-11-22T02:05:33.131750Z",
     "shell.execute_reply.started": "2025-11-22T02:05:33.131740Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1707, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-22T02:05:33.132630Z",
     "iopub.status.idle": "2025-11-22T02:05:33.132873Z",
     "shell.execute_reply": "2025-11-22T02:05:33.132752Z",
     "shell.execute_reply.started": "2025-11-22T02:05:33.132743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test.dropna(subset=['text'], inplace=True)\n",
    "df_test = df_test[['text']]   # remove 'id' column\n",
    "print(\"Test size:\", len(df_test))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-22T02:05:33.134793Z",
     "iopub.status.idle": "2025-11-22T02:05:33.135128Z",
     "shell.execute_reply": "2025-11-22T02:05:33.134944Z",
     "shell.execute_reply.started": "2025-11-22T02:05:33.134928Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_encodings = tokenizer(\n",
    "    df_test['text'].tolist(),\n",
    "    truncation=True,\n",
    "    padding='max_length',  \n",
    "    max_length=MAX_LEN,\n",
    "    return_tensors=None # keeps the lists (good for dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-22T02:05:33.135715Z",
     "iopub.status.idle": "2025-11-22T02:05:33.136049Z",
     "shell.execute_reply": "2025-11-22T02:05:33.135884Z",
     "shell.execute_reply.started": "2025-11-22T02:05:33.135869Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            key: torch.tensor(val[idx], dtype=torch.long)\n",
    "            for key, val in self.encodings.items()\n",
    "        }\n",
    "\n",
    "test_dataset = TestDataset(test_encodings)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-22T02:05:33.137163Z",
     "iopub.status.idle": "2025-11-22T02:05:33.137426Z",
     "shell.execute_reply": "2025-11-22T02:05:33.137303Z",
     "shell.execute_reply.started": "2025-11-22T02:05:33.137284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        \n",
    "        ids = batch[\"input_ids\"].to(device)\n",
    "        mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        # model returns logits directly\n",
    "        logits = model(\n",
    "            input_ids=ids,\n",
    "            attention_mask=mask\n",
    "        ) \n",
    "        \n",
    "\n",
    "        probs = torch.sigmoid(logits)     # convert to probability [0..1]\n",
    "\n",
    "        preds = (probs > 0.50).int().cpu()   # I have kept the threshold = 0.50\n",
    "        predictions.append(preds)\n",
    "\n",
    "predictions = torch.cat(predictions, dim=0)\n",
    "\n",
    "print(\"Predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T10:51:25.088532Z",
     "iopub.status.busy": "2025-11-21T10:51:25.088347Z",
     "iopub.status.idle": "2025-11-21T10:51:25.110711Z",
     "shell.execute_reply": "2025-11-21T10:51:25.110173Z",
     "shell.execute_reply.started": "2025-11-21T10:51:25.088517Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T10:51:25.112400Z",
     "iopub.status.busy": "2025-11-21T10:51:25.112205Z",
     "iopub.status.idle": "2025-11-21T10:51:25.126820Z",
     "shell.execute_reply": "2025-11-21T10:51:25.126357Z",
     "shell.execute_reply.started": "2025-11-21T10:51:25.112385Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "emotion_cols = ['anger', 'fear', 'joy', 'sadness', 'surprise']\n",
    "ids = np.arange(0, df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T10:51:25.127793Z",
     "iopub.status.busy": "2025-11-21T10:51:25.127579Z",
     "iopub.status.idle": "2025-11-21T10:51:25.145171Z",
     "shell.execute_reply": "2025-11-21T10:51:25.144653Z",
     "shell.execute_reply.started": "2025-11-21T10:51:25.127778Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(predictions.numpy(), columns=emotion_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T10:51:25.145984Z",
     "iopub.status.busy": "2025-11-21T10:51:25.145785Z",
     "iopub.status.idle": "2025-11-21T10:51:25.162811Z",
     "shell.execute_reply": "2025-11-21T10:51:25.162333Z",
     "shell.execute_reply.started": "2025-11-21T10:51:25.145947Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Adding the id column\n",
    "df_preds.insert(0,'id',ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T10:51:25.184597Z",
     "iopub.status.busy": "2025-11-21T10:51:25.184090Z",
     "iopub.status.idle": "2025-11-21T10:51:25.201939Z",
     "shell.execute_reply": "2025-11-21T10:51:25.201443Z",
     "shell.execute_reply.started": "2025-11-21T10:51:25.184580Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For re-assurance\n",
    "len(df_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T10:51:25.202939Z",
     "iopub.status.busy": "2025-11-21T10:51:25.202693Z",
     "iopub.status.idle": "2025-11-21T10:51:25.220680Z",
     "shell.execute_reply": "2025-11-21T10:51:25.220186Z",
     "shell.execute_reply.started": "2025-11-21T10:51:25.202915Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Converting it to the submission file.\n",
    "df_preds.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T10:51:25.222633Z",
     "iopub.status.busy": "2025-11-21T10:51:25.222440Z",
     "iopub.status.idle": "2025-11-21T10:51:25.241655Z",
     "shell.execute_reply": "2025-11-21T10:51:25.240981Z",
     "shell.execute_reply.started": "2025-11-21T10:51:25.222618Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Cleaining the GPU's history which ensures that it doesn't run slow with time."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13800781,
     "sourceId": 115439,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
